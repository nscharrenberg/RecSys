{"cells":[{"cell_type":"markdown","source":"## Importing","metadata":{"tags":[],"cell_id":"e2155cd6f84b423f823f3dc8f7b174ae","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom lenskit import batch, topn, util\nfrom lenskit.algorithms.user_knn import UserUser\nfrom lenskit.algorithms import Recommender\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score, mean_squared_error, mean_absolute_error\nimport sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import KNeighborsRegressor","metadata":{"tags":[],"cell_id":"8edfcf1d708942c0a651e0fa92323102","source_hash":"53525c8c","execution_start":1666353567932,"execution_millis":2019,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Functions","metadata":{"tags":[],"cell_id":"9e297a064c0441f497225ac2774b6ff8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"def data_wrangling_fix(dataset = pd.DataFrame([]), key=None, column=None, key_value = None, new_column_value = None):\n    dataset = dataset.copy()\n    \n    if key is None or column is None or key_value is None or new_column_value is None:\n        return\n    \n    dataset.loc[dataset[key] == key_value, column] = new_column_value\n\n    return dataset","metadata":{"tags":[],"cell_id":"64dc24374a2e49ce8b55e105bc12777b","source_hash":"cf9ead24","execution_start":1666353569954,"execution_millis":9,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def book_ratings_grouped_by(dataset = pd.DataFrame([]), key_to_group = None, rating_column = 'Book-Rating'):\n    if key_to_group is None:\n        return\n\n    book_ratings_grouped_by_key = dataset.groupby(key_to_group)[rating_column].count().sort_values(ascending=False)\n    book_ratings_grouped_by_key = pd.DataFrame(book_ratings_grouped_by_key)\n    book_ratings_grouped_by_key.rename(columns={'Book-Rating': 'Ratings-Count'}, inplace=True)\n    book_ratings_grouped_by_key = book_ratings_grouped_by_key.reset_index()\n\n    return book_ratings_grouped_by_key","metadata":{"tags":[],"cell_id":"135adc31ca4a4709ad34a6fc7864b805","source_hash":"1d507645","execution_start":1666353569968,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def group_and_merge_ratings(ratings = pd.DataFrame([]), items = pd.DataFrame([]), key_to_group = None):\n    if key_to_group is None:\n        return\n\n    book_ratings_grouped_by_key = book_ratings_grouped_by(ratings, key_to_group)\n    item_differences = items[items[key_to_group].isin(book_ratings_grouped_by_key[key_to_group])]\n    book_ratings_merged = pd.merge(item_differences[key_to_group], ratings, on=key_to_group, how='inner')\n\n    return book_ratings_merged","metadata":{"tags":[],"cell_id":"3eddf2602c594dc1baa6583e302a8bee","source_hash":"dd22dae9","execution_start":1666353569977,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def filter_items_of_book_ratings_by_threshold(dataset = pd.DataFrame([]), key=None, threshold=20, custom_merge=None):\n    items_grouped = book_ratings_grouped_by(dataset, key_to_group=key)\n    items_min_ratings = items_grouped[items_grouped['Ratings-Count'] > threshold]\n\n    dataset_to_merge = dataset\n\n    if custom_merge is not None:\n        dataset_to_merge = custom_merge\n\n    return pd.merge(items_min_ratings[key], dataset_to_merge, on=key), items_min_ratings","metadata":{"tags":[],"cell_id":"ac2e67d07cbb453ebe68053b1bb49e2a","source_hash":"2e9feab4","execution_start":1666353569989,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Reading","metadata":{"tags":[],"cell_id":"a70348945eee49538e50f7a01dab5b97","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"users = pd.read_csv('BX-Users.csv', sep=';', encoding='cp1252', on_bad_lines=\"skip\", low_memory=False)\nbooks = pd.read_csv('BX-Books.csv', sep=\";\", encoding='cp1252', on_bad_lines=\"skip\", low_memory=False)\nbook_ratings = pd.read_csv('BX-Book-Ratings.csv', sep=';', encoding='cp1252', on_bad_lines=\"skip\", low_memory=False)","metadata":{"tags":[],"cell_id":"f17db009cfcc4eb382c09e440fe4647c","source_hash":"b31b78","execution_start":1666353569993,"execution_millis":2920,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Solve Data Wrangling","metadata":{"tags":[],"cell_id":"025ec7a04a6b4e4db5696eab7fcb6e2d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"books = data_wrangling_fix(books, 'ISBN', 'Year-Of-Publication', '078946697X', 2000)\nbooks = data_wrangling_fix(books, 'ISBN', 'Book-Author', '078946697X', 'Michael Teitelbaum')\nbooks = data_wrangling_fix(books, 'ISBN', 'Publisher', '078946697X', 'DK Publishing Inc')\nbooks = data_wrangling_fix(books, 'ISBN', 'Book-Title', '078946697X', 'K Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)')\n\nbooks = data_wrangling_fix(books, 'ISBN', 'Year-Of-Publication', '0789466953', 2000)\nbooks = data_wrangling_fix(books, 'ISBN', 'Book-Author', '0789466953', 'James Buckley')\nbooks = data_wrangling_fix(books, 'ISBN', 'Publisher', '0789466953', 'DK Publishing Inc')\nbooks = data_wrangling_fix(books, 'ISBN', 'Book-Title', '0789466953', 'K Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)')\n\nbooks = data_wrangling_fix(books, 'ISBN', 'Year-Of-Publication', '2070426769', 2003)\nbooks = data_wrangling_fix(books, 'ISBN', 'Book-Author', '2070426769', 'jean-marie gustave le clÃ©zio')\nbooks = data_wrangling_fix(books, 'ISBN', 'Publisher', '2070426769', 'Gallimard')\nbooks = data_wrangling_fix(books, 'ISBN', 'Book-Title', '2070426769', 'Peuple du ciel, suivi de \"Les Bergers\"')","metadata":{"tags":[],"cell_id":"f255af86551144dc97511c092b031f4e","source_hash":"df150c87","execution_start":1666353572931,"execution_millis":625,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"books.drop(columns=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], inplace=True)\nbooks = books.astype({'ISBN': 'string', 'Book-Title': 'string', 'Book-Author': 'string', 'Publisher': 'string', 'Year-Of-Publication': np.uint32})","metadata":{"tags":[],"cell_id":"e145f8d1a8064e0693a53f709076cd2c","source_hash":"27692110","execution_start":1666353573561,"execution_millis":126,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"users = users.astype({'User-ID': 'Int64', 'Location': 'string', 'Age': 'Int64'})","metadata":{"tags":[],"cell_id":"e7471dba3d6244368d9a5d4369bde53b","source_hash":"c6ae5d7f","execution_start":1666353573711,"execution_millis":54,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Filter Data","metadata":{"tags":[],"cell_id":"99d2b131755f43efa3bbc1d6e575da57","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"book_ratings_books_merged = group_and_merge_ratings(book_ratings, books, 'ISBN')","metadata":{"tags":[],"cell_id":"9b43f704d68a4674a058b16c44b809d1","source_hash":"7d59fd05","execution_start":1666353573863,"execution_millis":1310,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"book_ratings_users_merged = group_and_merge_ratings(book_ratings, users, 'User-ID')","metadata":{"tags":[],"cell_id":"cad96d2fa7de4cdc832bed1ee3c80c75","source_hash":"e0fbebb5","execution_start":1666353575176,"execution_millis":236,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"book_ratings_nonzero = book_ratings_books_merged[book_ratings_books_merged['Book-Rating'] > 0]","metadata":{"tags":[],"cell_id":"8718ff6c77a14a2cb1ed237428b992f5","source_hash":"ae96ab7d","execution_start":1666353575414,"execution_millis":20,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"book_ratings_filtered, books_grouped_book_ratings_min_rating_count = filter_items_of_book_ratings_by_threshold(book_ratings_nonzero, 'ISBN', 20)","metadata":{"tags":[],"cell_id":"96e7e4a0c3c0421799a6200cc37b9bdf","source_hash":"6071fb45","execution_start":1666353575455,"execution_millis":282,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"book_ratings_filtered, users_grouped_book_ratings_min_rating_count = filter_items_of_book_ratings_by_threshold(book_ratings_filtered, 'User-ID', 20, custom_merge=book_ratings_filtered)","metadata":{"tags":[],"cell_id":"e1bed9ad18f3463ba303f9ea07b6e5a3","source_hash":"3137e8","execution_start":1666353575741,"execution_millis":23,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## User-Item Matrix","metadata":{"tags":[],"cell_id":"4b55a473a4014d6b8becda48f47beb80","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"book_rating_user_item_matrix = pd.DataFrame(book_ratings_filtered.copy())\nbook_rating_user_item_matrix.rename(columns={'User-ID': 'user', 'ISBN': 'item', 'Book-Rating': 'rating'}, inplace=True)","metadata":{"tags":[],"cell_id":"916b4bacd16e40d8bf277af6f13d2ac2","source_hash":"d80b8371","execution_start":1666353575770,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def build_user_based_cf(dataset, max_neighbors=30, min_neighbors=1):\n    user_user = UserUser(nnbrs=max_neighbors, min_nbrs=min_neighbors)\n    recsys = Recommender.adapt(user_user)\n    recsys.fit(dataset)\n\n    return recsys","metadata":{"tags":[],"cell_id":"0d29dac49a7e4e7c9befafe005d14a92","source_hash":"4f32d7c1","execution_start":1666353575774,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def evaluate(matrix, max_neighbors=30, min_neighbors=1, test_size=0.2, seed = None):\n    training_set, test_set = train_test_split(matrix, test_size=test_size, random_state=seed)\n\n    recsys = build_user_based_cf(training_set, min_neighbors=min_neighbors, max_neighbors=max_neighbors)\n\n    test_set['predicted_rating'] = recsys.predict(test_set)\n\n    test_set['relevant'] = test_set['rating'].apply(lambda x: 1 if x > 3 else 0)\n    test_set['predicted_relevant'] = test_set['predicted_rating'].apply(lambda x: 1 if x > 3 else 0)\n\n    y_test = pd.Series(test_set['relevant'])\n    y_pred = pd.Series(test_set['predicted_relevant'])\n\n    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n    rmse = mean_squared_error(y_test, y_pred, squared=False)\n    mae = mean_absolute_error(y_test, y_pred)\n\n    return precision, recall, fscore, rmse, mae","metadata":{"tags":[],"cell_id":"853915bed3874b8d89cb50cf31006145","source_hash":"495c00db","execution_start":1666353575782,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"enable_experiments = False\n\nif enable_experiments:\n    # Ensure the split is always the same for reproducability purposes\n    random_seed = 42\n\n    exp_book_ratings_threshold = [5, 10, 15, 20, 25, 30, 50, 75]\n    exp_user_ratings_threshold = [5, 10, 15, 20, 25, 30, 50, 75]\n    exp_min_neighbors_values = [1]\n    exp_max_neighbors_values = [20]\n    exp_test_size = [0.2]\n\n    exp_results = pd.DataFrame([], columns=['Book Ratings Threshold', 'User Ratings Threshold', 'Min Neighbors', 'Max Neighbors', 'Train-Test Split', 'Book Count', 'User Count', 'Rating Count', 'Precision', 'Recall', 'FScore', 'MRSE', 'MAE'])\n\n    for brt in exp_book_ratings_threshold:\n        for urt in exp_user_ratings_threshold:\n            for minnb in exp_min_neighbors_values:\n                for maxnb in exp_max_neighbors_values:\n                    if minnb > maxnb:\n                        continue\n\n                    for ts in exp_test_size:\n                        exp_dataset, exp_books_min_rating = filter_items_of_book_ratings_by_threshold(book_ratings_nonzero, 'ISBN', brt)\n                        exp_dataset, exp_users_min_rating = filter_items_of_book_ratings_by_threshold(exp_dataset, 'User-ID', urt)\n\n                        exp_dataset.rename(columns={'User-ID': 'user', 'ISBN': 'item', 'Book-Rating': 'rating'}, inplace=True)\n\n                        exp_precision, exp_recall, exp_fscore, exp_rmse, exp_mae = evaluate(exp_dataset, max_neighbors=maxnb, min_neighbors=minnb, test_size=ts, seed=random_seed)\n                        exp_results = pd.concat([exp_results, pd.DataFrame([{\n                            'Book Ratings Threshold': brt,\n                            'User Ratings Threshold': urt,\n                            'Min Neighbors': minnb,\n                            'Max Neighbors': maxnb,\n                            'Train-Test Split': ts,\n                            'Book Count': exp_dataset['item'].nunique(),\n                            'User Count': exp_dataset['user'].nunique(),\n                            'Rating Count': exp_dataset.size,\n                            'Precision': exp_precision,\n                            'Recall': exp_recall,\n                            'FScore': exp_fscore,\n                            'MRSE': exp_rmse,\n                            'MAE': exp_mae\n                        }])])\n\n                        print(f\"Finished {brt}-{urt}-{minnb}-{maxnb}-{ts}\")","metadata":{"tags":[],"cell_id":"56d7e2e6ef6f452c9570e32082fc60d6","source_hash":"f7d4d287","execution_start":1666353575792,"execution_millis":43,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#exp_results","metadata":{"tags":[],"cell_id":"1d6bdb337655410c9c587896b3b32680","source_hash":"cb767a","execution_start":1666353575835,"execution_millis":0,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":100,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Content-Boosting","metadata":{"tags":[],"cell_id":"4504fd67139f45dabdbc9d72a441aadb","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"def predict(user):\n    selected_user_ratings = book_ratings_CF.loc[book_ratings_CF['user'] == user]\n    number_ratings = len(selected_user_ratings)\n    \n    selected_user_rated_books = selected_user_ratings['item']\n    rated = books.loc[books['ISBN'].isin(selected_user_rated_books)]\n    rated_books = pd.DataFrame(rated)\n    rated_books.rename(columns = {'ISBN':'item'}, inplace = True)\n    rated_books_df = pd.merge(rated_books, selected_user_ratings, on = 'item', how = 'inner')\n    \n    selected_user_unrated_books = book_ratings_CF.loc[~book_ratings_CF['item'].isin(selected_user_rated_books)]\n    selected_user_unrated_books = selected_user_unrated_books['item']\n    unrated =  books.loc[books['ISBN'].isin(selected_user_unrated_books)]\n    unrated_books = pd.DataFrame(unrated)\n    unrated_books.rename(columns = {'ISBN':'item'}, inplace = True)\n    \n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(rated_books_df['Book-Title'])\n    y = rated_books_df['rating']\n    \n    neighbors = 2\n    \n    if (number_ratings < neighbors):\n        neighbors = number_ratings\n    neigh = KNeighborsRegressor(n_neighbors = neighbors)\n    neigh.fit(X, y)\n    \n    X_unrated = vectorizer.transform(unrated_books['Book-Title'])\n    y_unrated = neigh.predict(X_unrated)\n\n    unrated_books['predicted'] = y_unrated\n    unrated_books = unrated_books[['item', 'predicted']].copy()\n    return unrated_books","metadata":{"tags":[],"cell_id":"b45aa25800d04719b32af0f73dca6680","source_hash":"703d5ae7","execution_start":1666353575836,"execution_millis":16,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def fill_missing_ratings(user, matrix, predictions):\n    for i in predictions['item']:\n        if pd.isnull(matrix.loc[user, str(i)]):\n            matrix.loc[user, str(i)] = predictions.loc[predictions['item'] == i]['predicted'].item()\n    \n    return matrix","metadata":{"tags":[],"cell_id":"13a3168ec9cf4094a49c3ef8cd1119ec","source_hash":"78f8d965","execution_start":1666353575852,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def recompute_matrix(matrix):\n    for u in matrix.index:\n        predicted = predict(u)\n        matrix = fill_missing_ratings(u, matrix, predicted)\n    \n    return matrix","metadata":{"tags":[],"cell_id":"e07e6dbb96f2403e924d2bc7273ba75a","source_hash":"777f7be2","execution_start":1666353575853,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":22},{"cell_type":"code","source":"book_ratings_CF = pd.DataFrame(book_ratings_filtered)\nbook_ratings_CF.rename(columns = {'User-ID':'user' , 'ISBN' : 'item', 'Book-Rating' : 'rating'}, inplace = True)","metadata":{"tags":[],"cell_id":"0be01a1286cf48fa9e763b1391afef75","source_hash":"58b7c597","execution_start":1666353575854,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":23},{"cell_type":"code","source":"matrix = book_ratings_CF.pivot(index='user', columns='item', values='rating')","metadata":{"tags":[],"cell_id":"fcd79c37e22a44c5b6ce481470b4574f","source_hash":"10a1b674","execution_start":1666353575855,"execution_millis":17,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":24},{"cell_type":"code","source":"content_matrix = matrix.copy()\ncontent_matrix = recompute_matrix(content_matrix)","metadata":{"tags":[],"cell_id":"18ea73b4b8be486181dc4962a453a414","source_hash":"ef54b0cc","execution_start":1666353575873,"execution_millis":1100397,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":25},{"cell_type":"code","source":"book_ratings_new = content_matrix.reset_index().melt(id_vars='user', var_name='item', value_name='rating')","metadata":{"tags":[],"cell_id":"c651634b0c3f49e3b364c861803d6d82","source_hash":"82ad91d7","execution_start":1666354676271,"execution_millis":6,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":26},{"cell_type":"code","source":"enable_experiments = True\n\nif enable_experiments:\n    # Ensure the split is always the same for reproducability purposes\n    random_seed = 42\n\n    exp_book_ratings_threshold = [5, 10, 15, 20, 25, 30, 50, 75]\n    exp_user_ratings_threshold = [5, 10, 15, 20, 25, 30, 50, 75]\n    exp_min_neighbors_values = [1]\n    exp_max_neighbors_values = [20]\n    exp_test_size = [0.2]\n\n    boosted_exp_results = pd.DataFrame([], columns=['Book Ratings Threshold', 'User Ratings Threshold', 'Min Neighbors', 'Max Neighbors', 'Train-Test Split', 'Book Count', 'User Count', 'Rating Count', 'Precision', 'Recall', 'FScore', 'MRSE', 'MAE'])\n\n    for brt in exp_book_ratings_threshold:\n        for urt in exp_user_ratings_threshold:\n            for minnb in exp_min_neighbors_values:\n                for maxnb in exp_max_neighbors_values:\n                    if minnb > maxnb:\n                        continue\n\n                    for ts in exp_test_size:\n                        exp_precision, exp_recall, exp_fscore, exp_rmse, exp_mae = evaluate(book_ratings_new, max_neighbors=maxnb, min_neighbors=minnb, test_size=ts, seed=random_seed)\n                        boosted_exp_results = pd.concat([boosted_exp_results, pd.DataFrame([{\n                            'Book Ratings Threshold': brt,\n                            'User Ratings Threshold': urt,\n                            'Min Neighbors': minnb,\n                            'Max Neighbors': maxnb,\n                            'Train-Test Split': ts,\n                            'Book Count': book_ratings_new['item'].nunique(),\n                            'User Count': book_ratings_new['user'].nunique(),\n                            'Rating Count': book_ratings_new.size,\n                            'Precision': exp_precision,\n                            'Recall': exp_recall,\n                            'FScore': exp_fscore,\n                            'MRSE': exp_rmse,\n                            'MAE': exp_mae\n                        }])])\n\n                        print(f\"Finished {brt}-{urt}-{minnb}-{maxnb}-{ts}\")","metadata":{"tags":[],"cell_id":"c0665049b15243c5b7e4149606d601d9","source_hash":"eb67652","execution_start":1666354676327,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":27},{"cell_type":"code","source":"boosted_exp_results","metadata":{"tags":[],"cell_id":"8e7fb35827a54ffc94cd8a78dcbfbe08","source_hash":"38dbbf88","execution_start":1666354676328,"execution_millis":0,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":100,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":28},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"82d3d314da2f4407a9b1e753e8abc289","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c748b8c6-a06d-415c-803a-0d3a975a7798' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"f7a3da1aea1a418db33e923fefe57ae1","deepnote_execution_queue":[]}}