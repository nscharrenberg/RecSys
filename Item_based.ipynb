{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33972979",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.item_knn import ItemItem\n",
    "from scipy.sparse import csr_matrix\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix, roc_curve, auc, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper methods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def plot_roc_curve(roc_auc, fpr, tpr):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic example\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def item_explanation(recommended_books):\n",
    "    print(list(recommended_books['book_title']))\n",
    "    print(\"Based on your previous ratings we found books that similar to books which you have already rated.\")\n",
    "    if input(\"Do you want detailed description of your recommendation? y/n\") == 'y':\n",
    "        print(\"The algorithm computed predicted scores to demonstrate how the book fits with your preferences.\")\n",
    "        print(\"Above illustrated books and their predicted scores\")\n",
    "        print(recommended_books.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read & Analyze Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbeaaf78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Read datasets \n",
    "users = pd.read_csv('BX-Users.csv', sep = ';', encoding='cp1252')\n",
    "books = pd.read_csv('BX-Books.csv', sep=';', encoding='cp1252', on_bad_lines='skip', low_memory=False)\n",
    "book_ratings = pd.read_csv('BX-Book-Ratings.csv', sep=';', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e58ad209",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Shape:  (271360, 8)\n",
      "Book ratings Shape:  (1149780, 3)\n",
      "Users Shape:  (278858, 3)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of our datasets\n",
    "print(\"Books Shape: \", books.shape )\n",
    "print(\"Book ratings Shape: \", book_ratings.shape )\n",
    "print(\"Users Shape: \", users.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224d85f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books null information: \n",
      " ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            1\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n",
      "Book ratings null information: \n",
      " User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "Users null information: \n",
      " User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculating nulls in our datasets\n",
    "print(\"Books null information: \\n\", books.isnull().sum())\n",
    "print(\"Book ratings null information: \\n\", book_ratings.isnull().sum())\n",
    "print(\"Users null information: \\n\", users.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6be298",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dd0ee1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert all names of columns to lower case\n",
    "users.columns = users.columns.str.strip().str.lower().str.replace('-', '_')\n",
    "book_ratings.columns = book_ratings.columns.str.strip().str.lower().str.replace('-', '_')\n",
    "books.columns = books.columns.str.strip().str.lower().str.replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isbn                   0\n",
      "book_title             0\n",
      "book_author            0\n",
      "year_of_publication    0\n",
      "publisher              0\n",
      "user_id                0\n",
      "book_rating            0\n",
      "dtype: int64\n",
      "Books dataset shape:  (1031133, 7)\n",
      "Unique books in datasets:  270148\n"
     ]
    }
   ],
   "source": [
    "# Merge books and book ratings datasets together by ISBN\n",
    "books_dataset = books.merge(book_ratings, on=\"isbn\")\n",
    "# Drop nulls\n",
    "books_dataset = books_dataset.dropna(subset = ['book_author', 'publisher'])\n",
    "# Drop small and large images of books\n",
    "books_dataset = books_dataset.drop(columns=['image_url_s', 'image_url_l', 'image_url_m'], axis=1)\n",
    "# Reset indices\n",
    "books_dataset = books_dataset.reset_index(drop=True)\n",
    "print(books_dataset.isnull().sum())\n",
    "print(\"Books dataset shape: \", books_dataset.shape)\n",
    "print(\"Unique books in datasets: \", len(books_dataset.isbn.unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def preprocess_date(data, min_rating=10):\n",
    "    data_copy = data.copy()\n",
    "    # Calculate how many books with 0 ratings we have\n",
    "    zero_ratings = data_copy[data_copy['book_rating'] == 0]\n",
    "    # print(\"Total number of books with zero ratings: \", zero_ratings.shape)\n",
    "    # Remove books with zero ratings\n",
    "    data_copy = data_copy.drop(index=zero_ratings.index)\n",
    "    data_copy = data_copy.reset_index(drop=True)\n",
    "    # print(\"Unique books in datasets: \", len(books_dataset.isbn.unique()))\n",
    "    # print(\"Books dataset shape after dropping 0 ratings: \", books_dataset.shape)\n",
    "\n",
    "    # Calculate how many times users rated books\n",
    "    # users_ratings_count = pd.DataFrame(books_dataset['user_id'].value_counts())\n",
    "    #\n",
    "    # urc_indices = users_ratings_count[users_ratings_count['user_id'] >= 10].index\n",
    "    # print(\"Users which rated at least 10 books = \", len(urc_indices.values))\n",
    "    # books_dataset = books_dataset[books_dataset['user_id'].isin(urc_indices)]\n",
    "    # books_dataset = books_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Calculate how many times books were rated\n",
    "    books_ratings_count = pd.DataFrame(data_copy['isbn'].value_counts())\n",
    "\n",
    "    brc_indices = books_ratings_count[books_ratings_count['isbn'] >= min_rating].index\n",
    "    # print(\"Books which were rated at least 50 times = \",len(brc_indices.values))\n",
    "    data_copy = data_copy[data_copy['isbn'].isin(brc_indices)]\n",
    "    data_copy = data_copy.reset_index(drop=True)\n",
    "    data_copy = data_copy.rename(columns={'isbn':'item', 'user_id':'user', 'book_rating':'rating'})\n",
    "    return data_copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "books = books.rename(columns={'isbn':'item'})\n",
    "\n",
    "# print(\"Books dataset shape after dropping books with less than 50 ratings: \", books_dataset.shape)\n",
    "\n",
    "# books_dataset.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "         isbn           book_title           book_author year_of_publication  \\\n0  0195153448  Classical Mythology    Mark P. O. Morford                2002   \n1  0002005018         Clara Callan  Richard Bruce Wright                2001   \n2  0002005018         Clara Callan  Richard Bruce Wright                2001   \n\n                 publisher  user_id  book_rating  \n0  Oxford University Press        2            0  \n1    HarperFlamingo Canada        8            5  \n2    HarperFlamingo Canada    11400            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>book_title</th>\n      <th>book_author</th>\n      <th>year_of_publication</th>\n      <th>publisher</th>\n      <th>user_id</th>\n      <th>book_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0195153448</td>\n      <td>Classical Mythology</td>\n      <td>Mark P. O. Morford</td>\n      <td>2002</td>\n      <td>Oxford University Press</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002005018</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001</td>\n      <td>HarperFlamingo Canada</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002005018</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001</td>\n      <td>HarperFlamingo Canada</td>\n      <td>11400</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Converting our dataframe to scipy sparse matrix\n",
    "# books_features = books_dataset.pivot(\n",
    "#     index='item',\n",
    "#     columns='user',\n",
    "#     values='rating'\n",
    "# ).fillna(0)\n",
    "#\n",
    "# mat_books_features = csr_matrix(books_features.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# books_features.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Item-Based Collaborative Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Testing information dataset\n",
    "test_data = pd.DataFrame(columns=[\"unique_books\", \"unique_users\", \"min_books_rating\", \"min_neighbours\", \"max_neighbours\", \"test_size\", \"precision\", \"recall\", \"fscore\", \"accuracy\", \"confussion_matrix\", \"rmse\", \"mae\", \"fpr\", \"tpr\", \"roc_auc\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def evaluate_model_item_based_individual(data, max_nbrs=30, min_nbrs=1, test_size=0.2):\n",
    "    train_df, test_df = train_test_split(data, test_size=test_size)\n",
    "\n",
    "    item_item = ItemItem(max_nbrs, min_nbrs=min_nbrs)\n",
    "    recsys = Recommender.adapt(item_item)\n",
    "    recsys.fit(train_df)\n",
    "\n",
    "    test_df['predicted_rating'] = recsys.predict(test_df)\n",
    "\n",
    "    test_df['relevant'] = test_df['rating'].apply(lambda x: 1 if x>3 else 0)\n",
    "    test_df['predicted_relevant'] = test_df['predicted_rating'].apply(lambda x: 1 if x>3 else 0)\n",
    "\n",
    "    y_test = list(test_df['relevant'])\n",
    "    y_pred = list(test_df['predicted_relevant'])\n",
    "    # precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n",
    "    # fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return rmse, mae\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "testing = False\n",
    "if testing:\n",
    "    min_rating = [10, 15, 20, 25, 30, 35]\n",
    "    min_nbrs = [1]\n",
    "    max_nbrs = [12]\n",
    "    test_size = [0.2]\n",
    "    for mr in min_rating:\n",
    "        for min_n in min_nbrs:\n",
    "            for max_n in max_nbrs:\n",
    "                if min_n > max_n:\n",
    "                        continue\n",
    "                for ts in test_size:\n",
    "                    data_tmp = preprocess_date(books_dataset, min_rating=mr)\n",
    "                    rmse, mae = evaluate_model_item_based_individual(data_tmp, max_nbrs=max_n, min_nbrs=min_n, test_size=ts)\n",
    "\n",
    "                    print(str(mr) + \" \" + str(min_n) + \" \" + str(max_n) + \" \" +  str(ts))\n",
    "                    new_row = {\"unique_books\": len(data_tmp.item.unique()), \"unique_users\": len(data_tmp.user.unique()), \"min_books_rating\": mr, \"min_neighbours\": min_n, \"max_neighbours\": max_n, \"test_size\": ts, \"rmse\": rmse, \"mae\": mae}\n",
    "\n",
    "                    test_data = test_data.append(new_row , ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# test_data = test_data.sort_values(by='rmse', ascending=True).reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# compression_opts = dict(method='zip',\n",
    "#                         archive_name='out.csv')\n",
    "# test_data.to_csv('out.zip', index=False,\n",
    "#           compression=compression_opts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recommendation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def item_based(data, selected_user, num_recs=10, max_nbrs=12, min_nbrs=1):\n",
    "    # We use the collaborative item algorithm ItemItem, that use the nearest neighbors\n",
    "    item_item = ItemItem(max_nbrs, min_nbrs=min_nbrs)  # Minimum (3) and maximum (15) number of neighbors to consider\n",
    "    recsys = Recommender.adapt(item_item)\n",
    "    recsys.fit(data)\n",
    "    recommended_books = recsys.recommend(selected_user, num_recs) # generate 10 recommendations for the selected user\n",
    "    selected_books_item_item = pd.merge(data, recommended_books, on='item', how = 'inner')\n",
    "    selected_books_item_item = selected_books_item_item.drop_duplicates(subset='item')\n",
    "    selected_books_item_item = selected_books_item_item.drop(columns=['rating'], axis=1)\n",
    "    selected_books_item_item = selected_books_item_item.reset_index(drop=True)\n",
    "    item_explanation(selected_books_item_item)\n",
    "    return selected_books_item_item"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not load LIBBLAS: Could not find module 'libblas' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "Numba is using threading layer omp - consider TBB\n",
      "found 1 potential runtime problems - see https://boi.st/lkpy-perf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Giver (Readers Circle)', 'Love You Forever', 'The Godfather', 'The Lord of the Rings (Movie Art Cover)', 'The Two Towers (The Lord of the Rings, Part 2)', 'The Fellowship of the Ring (The Lord of the Rings, Part 1)', 'Illusions', \"Sabine's Notebook: In Which the Extraordinary Correspondence of Griffin &amp; Sabine Continues\", 'Patriot Games (Jack Ryan Novels)', 'Vector']\n",
      "Based on your previous ratings we found books that similar to books which you have already rated.\n",
      "The algorithm computed predicted scores to demonstrate how the book fits with your preferences.\n",
      "Above illustrated books and their predicted scores\n",
      "         item                                         book_title  \\\n",
      "0  0440237688                         The Giver (Readers Circle)   \n",
      "1  0920668372                                   Love You Forever   \n",
      "2  0451167716                                      The Godfather   \n",
      "3  0618129022            The Lord of the Rings (Movie Art Cover)   \n",
      "4  0618002235     The Two Towers (The Lord of the Rings, Part 2)   \n",
      "5  0618002227  The Fellowship of the Ring (The Lord of the Ri...   \n",
      "6  0440343194                                          Illusions   \n",
      "7  0811801802  Sabine's Notebook: In Which the Extraordinary ...   \n",
      "8  0425109720                   Patriot Games (Jack Ryan Novels)   \n",
      "9  0425172996                                             Vector   \n",
      "\n",
      "        book_author year_of_publication                 publisher   user  \\\n",
      "0        LOIS LOWRY                2002               Laurel Leaf   1554   \n",
      "1  Robert N. Munsch                1986         Firefly Books Ltd   2033   \n",
      "2        Mario Puzo                2004               Signet Book   5268   \n",
      "3    J.R.R. Tolkien                2001  Houghton Mifflin Company   5539   \n",
      "4  J. R. R. Tolkien                1999  Houghton Mifflin Company  11944   \n",
      "5  J. R. R. Tolkien                1999  Houghton Mifflin Company    254   \n",
      "6      Richard Bach                1981     Bantam Doubleday Dell  13698   \n",
      "7      Nick Bantock                1992           Chronicle Books   6575   \n",
      "8        Tom Clancy                1992  Berkley Publishing Group  18172   \n",
      "9        Robin Cook                2000  Berkley Publishing Group  16795   \n",
      "\n",
      "       score  \n",
      "0   9.761378  \n",
      "1  10.952489  \n",
      "2   9.903274  \n",
      "3   9.513761  \n",
      "4  10.435081  \n",
      "5   9.631770  \n",
      "6  10.002220  \n",
      "7   9.501711  \n",
      "8   9.761378  \n",
      "9   9.898822  \n"
     ]
    }
   ],
   "source": [
    "data_individual = preprocess_date(books_dataset, min_rating=25)\n",
    "recommendations = item_based(data_individual, int(data_individual.sample(n=1)['user']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aggregation Strategies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Approval voting strategy (Majority Based)\n",
    "def approval_voting_stg(recommended_books, threshold):\n",
    "    # Drop all books below threshold\n",
    "    recommended_books = recommended_books[recommended_books['predicted_rating'] > threshold]\n",
    "    # Calculate votes to each book\n",
    "    recommended_books = pd.DataFrame(recommended_books['item'].value_counts())\n",
    "    # Sort in descending order (max to min)\n",
    "    recommended_books = recommended_books.sort_values(by='item', ascending=False).reset_index(drop=True)\n",
    "    return recommended_books\n",
    "\n",
    "# Average strategy (Consensus based)\n",
    "def average_stg(recommended_books, group_size):\n",
    "    # Calculate average scores for each book\n",
    "    recommended_books = recommended_books.groupby(['item'])['predicted_rating'].sum() / group_size\n",
    "\n",
    "    # Sort in descending order (max to min)\n",
    "    # recommended_books = recommended_books.sort_values(by='predicted_rating', ascending=False).reset_index(drop=True)\n",
    "    return recommended_books\n",
    "\n",
    "# Most pleasure strategy (Borderline)\n",
    "def most_pleasure_stg(recommended_books):\n",
    "    # Find the maximum score for each book\n",
    "    recommended_books = recommended_books.groupby(['item']).max().reset_index(drop=True)\n",
    "    # Sort in descending order (max to min)\n",
    "    recommended_books = recommended_books.sort_values(by='predicted_rating', ascending=False).reset_index(drop=True)\n",
    "    return recommended_books"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Group Recommendation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def item_based_group(data, group_size=10, agg_strategy=2):\n",
    "    # Select random sample\n",
    "    random_selected = list(data.sample(n=group_size).reset_index(drop=True)['user'])\n",
    "\n",
    "    # Select remained users\n",
    "    remained_users = list(data.user.unique())\n",
    "    for i in random_selected:\n",
    "        remained_users.remove(i)\n",
    "\n",
    "    # Create unseen books with random user for prediction\n",
    "    unseen_books = data[data['user'].isin(remained_users)]\n",
    "    unseen_books = unseen_books.drop(columns=['user', 'rating'], axis=1)\n",
    "    unseen_books = unseen_books.drop_duplicates(subset='item')\n",
    "    unseen_books_group = pd.DataFrame()\n",
    "    for i in random_selected:\n",
    "        unseen_books['user'] = i\n",
    "        unseen_books_group = unseen_books_group.append(unseen_books)\n",
    "    unseen_books_group = unseen_books_group.reset_index(drop=True)\n",
    "\n",
    "    # Item Item CF\n",
    "    item_item = ItemItem(10, min_nbrs=1)\n",
    "    recsys = Recommender.adapt(item_item)\n",
    "    recsys.fit(data)\n",
    "\n",
    "    unseen_books_group['predicted_rating'] = recsys.predict(unseen_books_group)\n",
    "\n",
    "    # Drop nulls\n",
    "    group_unseen_books = unseen_books_group.dropna(subset = ['predicted_rating'])\n",
    "\n",
    "    # Drop books with null in matrix\n",
    "    group_unseen_books_count = pd.DataFrame(group_unseen_books['item'].value_counts())\n",
    "\n",
    "    gun_indices = group_unseen_books_count[group_unseen_books_count['item'] == group_size].index\n",
    "\n",
    "    group_unseen_books = group_unseen_books[group_unseen_books['item'].isin(gun_indices)]\n",
    "\n",
    "    # # Converting our dataframe to scipy sparse matrix\n",
    "    # books_features = group_unseen_books.pivot(\n",
    "    #     index='item',\n",
    "    #     columns='user',\n",
    "    #     values='predicted_rating'\n",
    "    # ).fillna(0)\n",
    "\n",
    "    if agg_strategy == 1:\n",
    "        recommendation = approval_voting_stg(group_unseen_books, 6)\n",
    "    elif agg_strategy == 2:\n",
    "        recommendation = average_stg(group_unseen_books, group_size)\n",
    "    else:\n",
    "        recommendation = most_pleasure_stg(group_unseen_books)\n",
    "\n",
    "    return recommendation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n",
      "C:\\Users\\dika1\\AppData\\Local\\Temp\\ipykernel_9172\\2947111557.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  unseen_books_group = unseen_books_group.append(unseen_books)\n"
     ]
    },
    {
     "data": {
      "text/plain": "item\n006000438X    6.979271\n0060929871    7.185851\n0060930535    7.637784\n0060934417    7.795019\n0060959037    7.934099\n0060977493    7.156123\n014023313X    6.891096\n0312201656    7.254784\n0312278586    6.868768\n0312924585    8.063210\nName: predicted_rating, dtype: float64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group = preprocess_date(books_dataset, min_rating=25)\n",
    "\n",
    "group_recommendation = item_based_group(data_group)\n",
    "group_recommendation.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}